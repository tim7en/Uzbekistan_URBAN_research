#!/usr/bin/env python3
"""
Comprehensive Vulnerability Assessment Debug Report
Analyzes all parameters used in the IPCC AR6 climate risk assessment
"""

import json
from datetime import datetime

def generate_vulnerability_debug_report():
    # Load the assessment results
    with open('D:/Dev/Uzbekistan_URBAN_research/suhi_analysis_output/climate_assessment/climate_risk_assessment_results.json', 'r') as f:
        data = json.load(f)
    
    report_lines = []
    report_lines.append("=" * 80)
    report_lines.append("COMPREHENSIVE VULNERABILITY ASSESSMENT DEBUG REPORT")
    report_lines.append("=" * 80)
    report_lines.append(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append(f"Cities analyzed: {len(data)}")
    report_lines.append("")
    
    # Define all assessment components
    hazard_components = [
        'heat_hazard', 'dry_hazard', 'dust_hazard', 'pluvial_hazard', 'air_quality_hazard'
    ]
    
    exposure_components = [
        'population_exposure', 'gdp_exposure', 'viirs_exposure'
    ]
    
    vulnerability_components = [
        'income_vulnerability', 'veg_access_vulnerability', 'fragmentation_vulnerability',
        'bio_trend_vulnerability', 'air_pollution_vulnerability', 'water_access_vulnerability',
        'healthcare_access_vulnerability', 'education_access_vulnerability', 
        'sanitation_vulnerability', 'building_age_vulnerability'
    ]
    
    adaptive_capacity_components = [
        'gdp_adaptive_capacity', 'greenspace_adaptive_capacity', 'services_adaptive_capacity',
        'air_quality_adaptive_capacity', 'social_infrastructure_capacity', 'water_system_capacity'
    ]
    
    # 1. SUMMARY STATISTICS
    report_lines.append("1. SUMMARY STATISTICS BY COMPONENT")
    report_lines.append("=" * 50)
    
    all_components = hazard_components + exposure_components + vulnerability_components + adaptive_capacity_components
    
    for component in all_components:
        values = [data[city].get(component, 0) for city in data.keys()]
        min_val = min(values)
        max_val = max(values)
        avg_val = sum(values) / len(values)
        
        # Find cities with min and max values
        min_city = [city for city in data.keys() if data[city].get(component, 0) == min_val][0]
        max_city = [city for city in data.keys() if data[city].get(component, 0) == max_val][0]
        
        report_lines.append(f"{component}:")
        report_lines.append(f"  Range: {min_val:.3f} ({min_city}) - {max_val:.3f} ({max_city})")
        report_lines.append(f"  Average: {avg_val:.3f}")
        
        # Check for suspicious patterns (all same value)
        unique_values = len(set(round(v, 3) for v in values))
        if unique_values == 1:
            report_lines.append(f"  ‚ö†Ô∏è  WARNING: All cities have identical values!")
        elif unique_values <= 3:
            report_lines.append(f"  ‚ö†Ô∏è  WARNING: Only {unique_values} unique values across all cities")
        
        report_lines.append("")
    
    # 2. DETAILED CITY-BY-CITY ANALYSIS
    report_lines.append("2. DETAILED CITY-BY-CITY VULNERABILITY ANALYSIS")
    report_lines.append("=" * 60)
    
    # Sort cities by overall risk for analysis
    city_risks = [(city, data[city]['overall_risk_score']) for city in data.keys()]
    city_risks.sort(key=lambda x: x[1], reverse=True)
    
    for city, risk_score in city_risks:
        city_data = data[city]
        report_lines.append(f"\n{city.upper()} (Risk: {risk_score:.3f}, Adaptability: {city_data['adaptability_score']:.3f})")
        report_lines.append("-" * 40)
        
        # Basic characteristics
        report_lines.append(f"Population: {city_data['population']:,} | GDP: ${city_data['gdp_per_capita_usd']:,.0f} | Area: {city_data.get('built_area_percentage', 0):.1f}% built")
        
        # Hazard components
        report_lines.append("HAZARDS:")
        for component in hazard_components:
            value = city_data.get(component, 0)
            level = "HIGH" if value > 0.7 else "MED" if value > 0.4 else "LOW"
            report_lines.append(f"  {component}: {value:.3f} ({level})")
        
        # Exposure components  
        report_lines.append("EXPOSURE:")
        for component in exposure_components:
            value = city_data.get(component, 0)
            level = "HIGH" if value > 0.7 else "MED" if value > 0.4 else "LOW"
            report_lines.append(f"  {component}: {value:.3f} ({level})")
        
        # Vulnerability components
        report_lines.append("VULNERABILITIES:")
        for component in vulnerability_components:
            value = city_data.get(component, 0)
            level = "HIGH" if value > 0.7 else "MED" if value > 0.4 else "LOW"
            report_lines.append(f"  {component}: {value:.3f} ({level})")
        
        # Adaptive capacity components
        report_lines.append("ADAPTIVE CAPACITY:")
        for component in adaptive_capacity_components:
            value = city_data.get(component, 0)
            level = "HIGH" if value > 0.7 else "MED" if value > 0.4 else "LOW"
            report_lines.append(f"  {component}: {value:.3f} ({level})")
    
    # 3. CONTRADICTION ANALYSIS
    report_lines.append("\n\n3. CONTRADICTION ANALYSIS")
    report_lines.append("=" * 40)
    report_lines.append("Identifying logical inconsistencies in the assessment:")
    report_lines.append("")
    
    contradictions = []
    
    for city in data.keys():
        city_data = data[city]
        
        # Air quality contradiction
        air_hazard = city_data.get('air_quality_hazard', 0)
        air_vuln = city_data.get('air_pollution_vulnerability', 0)
        if air_hazard > 0.8 and air_vuln < 0.5:
            contradictions.append(f"{city}: High air quality hazard ({air_hazard:.3f}) but low air pollution vulnerability ({air_vuln:.3f})")
        
        # Economic contradiction
        gdp_per_cap = city_data.get('gdp_per_capita_usd', 0)
        income_vuln = city_data.get('income_vulnerability', 0)
        if gdp_per_cap > 3000 and income_vuln > 0.5:
            contradictions.append(f"{city}: High GDP per capita (${gdp_per_cap:.0f}) but high income vulnerability ({income_vuln:.3f})")
        
        # Small city bias
        population = city_data.get('population', 0)
        exposure = city_data.get('exposure_score', 0)
        adaptability = city_data.get('adaptability_score', 0)
        if population < 100000 and exposure < 0.2 and adaptability > 0.5:
            contradictions.append(f"{city}: Small city bias - low exposure ({exposure:.3f}) may inflate adaptability ({adaptability:.3f})")
    
    if contradictions:
        for contradiction in contradictions:
            report_lines.append(f"‚ö†Ô∏è  {contradiction}")
    else:
        report_lines.append("‚úÖ No major contradictions detected")
    
    # 4. METHODOLOGICAL ISSUES
    report_lines.append("\n\n4. METHODOLOGICAL ISSUES IDENTIFIED")
    report_lines.append("=" * 45)
    
    issues = []
    
    # Check for hardcoded values
    for component in all_components:
        values = [data[city].get(component, 0) for city in data.keys()]
        unique_values = len(set(round(v, 3) for v in values))
        if unique_values == 1:
            issues.append(f"All cities have identical {component} values ({values[0]:.3f}) - likely hardcoded")
        elif unique_values <= 2:
            issues.append(f"Only {unique_values} unique values for {component} - insufficient variation")
    
    # Check for extreme values
    for city in data.keys():
        city_data = data[city]
        
        # Check if any component is exactly 0 or 1 (suspicious)
        for component in all_components:
            value = city_data.get(component, 0)
            if value == 1.0:
                issues.append(f"{city} has {component} = 1.000 (maximum value - check if realistic)")
            elif value == 0.0 and component not in ['income_vulnerability', 'surface_water_change']:
                issues.append(f"{city} has {component} = 0.000 (minimum value - check if realistic)")
    
    if issues:
        for issue in issues:
            report_lines.append(f"üîç {issue}")
    else:
        report_lines.append("‚úÖ No major methodological issues detected")
    
    # 5. RECOMMENDATIONS
    report_lines.append("\n\n5. RECOMMENDATIONS FOR IMPROVEMENT")
    report_lines.append("=" * 40)
    
    recommendations = [
        "1. Review air pollution vulnerability calculation - should correlate with air quality hazard",
        "2. Consider weighting economic capacity more heavily in final adaptability score",
        "3. Implement size-adjusted exposure metrics to reduce small city bias",
        "4. Add cross-validation checks for contradictory component values",
        "5. Use percentile ranking for all components to ensure proper distribution",
        "6. Consider local context factors (e.g., industrial cities, mining towns)",
        "7. Validate component calculations against ground truth data where available"
    ]
    
    for rec in recommendations:
        report_lines.append(rec)
    
    # Write report to file
    report_text = '\n'.join(report_lines)
    
    with open('D:/Dev/Uzbekistan_URBAN_research/vulnerability_assessment_debug_report.txt', 'w', encoding='utf-8') as f:
        f.write(report_text)
    
    print("‚úÖ Comprehensive Vulnerability Assessment Debug Report generated!")
    print("üìÅ Saved to: vulnerability_assessment_debug_report.txt")
    print(f"üìä Report contains {len(report_lines)} lines of analysis")
    print("\nKey findings preview:")
    print("=" * 40)
    
    # Show preview of contradictions
    contradiction_count = len([line for line in report_lines if '‚ö†Ô∏è' in line])
    issue_count = len([line for line in report_lines if 'üîç' in line])
    
    print(f"‚ö†Ô∏è  {contradiction_count} contradictions identified")
    print(f"üîç {issue_count} methodological issues found")
    print(f"üèôÔ∏è  {len(data)} cities analyzed across {len(all_components)} parameters")

if __name__ == "__main__":
    generate_vulnerability_debug_report()
