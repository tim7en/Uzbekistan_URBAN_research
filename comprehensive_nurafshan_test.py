#!/usr/bin/env python3
"""
Comprehensive test of all metrics used for Nurafshan city analysis.
Shows why Nurafshan has low exposure score and tests all components.
"""

import json
import os
from services.climate_data_loader import ClimateDataLoader
from services.climate_risk_assessment import IPCCRiskAssessmentService

def test_all_nurafshan_metrics():
    """Comprehensive test of all metrics for Nurafshan"""
    
    print("="*80)
    print("COMPREHENSIVE NURAFSHAN METRICS TEST")
    print("="*80)
    
    city = "Nurafshon"
    
    # Initialize services
    loader = ClimateDataLoader("suhi_analysis_output")
    service = IPCCRiskAssessmentService(loader)
    
    print(f"\nğŸ™ï¸  ANALYZING: {city}")
    print("="*50)
    
    # Get population data
    population_data = service.data['population_data'].get(city)
    
    print("\n1. BASIC CITY PROFILE:")
    print("-" * 30)
    if population_data:
        print(f"ğŸ“Š Population: {population_data.population_2024:,}")
        print(f"ğŸ“Š GDP per capita: ${population_data.gdp_per_capita_usd:,.2f}")
        print(f"ğŸ“Š Density: {population_data.density_per_km2:.1f} people/kmÂ²")
        print(f"ğŸ“Š Total GDP: ${population_data.population_2024 * population_data.gdp_per_capita_usd:,.0f}")
        
    print("\n2. COMPARATIVE RANKINGS (among 14 cities):")
    print("-" * 45)
    
    # Show where Nurafshan ranks
    all_cities = []
    for city_name, pop_data in service.data['population_data'].items():
        all_cities.append({
            'city': city_name,
            'population': pop_data.population_2024,
            'density': pop_data.density_per_km2,
            'gdp_total': pop_data.population_2024 * pop_data.gdp_per_capita_usd,
            'gdp_per_capita': pop_data.gdp_per_capita_usd
        })
    
    # Sort by population
    all_cities.sort(key=lambda x: x['population'], reverse=True)
    nurafshan_pop_rank = next(i for i, c in enumerate(all_cities) if c['city'] == city) + 1
    
    # Sort by density  
    all_cities.sort(key=lambda x: x['density'], reverse=True)
    nurafshan_density_rank = next(i for i, c in enumerate(all_cities) if c['city'] == city) + 1
    
    # Sort by total GDP
    all_cities.sort(key=lambda x: x['gdp_total'], reverse=True)
    nurafshan_gdp_rank = next(i for i, c in enumerate(all_cities) if c['city'] == city) + 1
    
    print(f"ğŸ† Population rank: {nurafshan_pop_rank}/14 (smallest)")
    print(f"ğŸ† Density rank: {nurafshan_density_rank}/14 (lowest)")
    print(f"ğŸ† Total GDP rank: {nurafshan_gdp_rank}/14")
    
    print("\n3. EXPOSURE COMPONENTS ANALYSIS:")
    print("-" * 35)
    
    # Calculate each exposure component
    cache = service.data['cache']
    
    # Population exposure
    pop_exposure = loader.pct_norm(cache['population'], population_data.population_2024)
    print(f"ğŸ“Š Population Exposure: {pop_exposure:.3f} (weight: 40%)")
    
    # Density exposure
    density_exposure = loader.pct_norm(cache['density'], population_data.density_per_km2)
    print(f"ğŸ“Š Density Exposure: {density_exposure:.3f} (weight: 25%)")
    
    # Built environment exposure
    built_exposure = 0
    for lulc_city in service.data['lulc_data']:
        if lulc_city.get('city') == city:
            areas = lulc_city.get('areas_m2', {})
            if areas:
                latest_year = max(areas.keys(), key=lambda x: int(x))
                built_pct = areas[latest_year].get('Built_Area', {}).get('percentage', 0)
                built_exposure = loader.pct_norm(cache['built_pct'], built_pct)
                print(f"ğŸ“Š Built Environment Exposure: {built_exposure:.3f} (weight: 20%)")
                print(f"    Built area: {built_pct:.2f}% in {latest_year}")
            break
    
    # Economic activity exposure (nightlights)
    nightlight_exposure = 0
    for nl_city in service.data['nightlights_data']:
        if nl_city.get('city') == city:
            years_data = nl_city.get('years', {})
            if years_data:
                latest_year = max(years_data.keys(), key=lambda x: int(x))
                urban_nl = years_data[latest_year].get('stats', {}).get('urban_core', {}).get('mean', 0)
                nightlight_exposure = loader.pct_norm(cache['nightlights'], urban_nl)
                print(f"ğŸ“Š Economic Activity Exposure: {nightlight_exposure:.3f} (weight: 15%)")
                print(f"    Nightlight intensity: {urban_nl:.2f} in {latest_year}")
            break
    
    # Calculate weighted exposure
    total_exposure = (0.4 * pop_exposure + 0.25 * density_exposure + 
                     0.2 * built_exposure + 0.15 * nightlight_exposure)
    print(f"\nğŸ¯ TOTAL EXPOSURE SCORE: {total_exposure:.3f}")
    print(f"   Calculation: 0.4Ã—{pop_exposure:.3f} + 0.25Ã—{density_exposure:.3f} + 0.2Ã—{built_exposure:.3f} + 0.15Ã—{nightlight_exposure:.3f}")
    
    print("\n4. OTHER CLIMATE DATA COMPONENTS:")
    print("-" * 35)
    
    # Temperature data
    temp_file = f"suhi_analysis_output/temperature/{city}_temperature_metrics.json"
    if os.path.exists(temp_file):
        with open(temp_file, 'r') as f:
            temp_data = json.load(f)
        summer_temp = temp_data.get('summer_season_summary', {}).get('mean_LST_C', 'N/A')
        annual_temp = temp_data.get('annual_summary', {}).get('mean_LST_C', 'N/A')
        print(f"ğŸŒ¡ï¸  Summer Temperature: {summer_temp}Â°C")
        print(f"ğŸŒ¡ï¸  Annual Temperature: {annual_temp}Â°C")
    
    # SUHI data
    suhi_file = f"suhi_analysis_output/suhi/{city}_suhi_metrics.json"
    if os.path.exists(suhi_file):
        with open(suhi_file, 'r') as f:
            suhi_data = json.load(f)
        summer_suhi = suhi_data.get('summer_season_summary', {}).get('suhi_intensity', 'N/A')
        print(f"ğŸï¸  Summer SUHI Intensity: {summer_suhi}Â°C")
    
    # Air quality
    aq_file = f"suhi_analysis_output/air_quality/{city}_air_quality_metrics.json"
    if os.path.exists(aq_file):
        with open(aq_file, 'r') as f:
            aq_data = json.load(f)
        if 'metrics' in aq_data and 'annual' in aq_data['metrics']:
            annual = aq_data['metrics']['annual']
            pm25 = annual.get('PM2_5', 'N/A')
            print(f"ğŸ’¨ PM2.5: {pm25} Î¼g/mÂ³")
    
    # Water scarcity
    ws_file = f"suhi_analysis_output/water_scarcity/{city}_water_scarcity_assessment.json"
    if os.path.exists(ws_file):
        with open(ws_file, 'r') as f:
            ws_data = json.load(f)
        aridity = ws_data.get('aridity_index', 'N/A')
        print(f"ğŸ’§ Aridity Index: {aridity}")
    
    # Social infrastructure
    social_file = f"suhi_analysis_output/social_sector/{city}_social_sector.json"
    if os.path.exists(social_file):
        with open(social_file, 'r') as f:
            social_data = json.load(f)
        schools = social_data.get('infrastructure_counts', {}).get('schools', 'N/A')
        hospitals = social_data.get('infrastructure_counts', {}).get('hospitals', 'N/A')
        print(f"ğŸ¥ Healthcare: {hospitals} hospitals")
        print(f"ğŸ« Education: {schools} schools")
    
    print("\n5. FULL CLIMATE RISK ASSESSMENT:")
    print("-" * 35)
    
    try:
        # Get the result as ClimateRiskMetrics object
        metrics = service._assess_city_internal(city)
        
        print(f"ğŸ¯ FINAL SCORES:")
        print(f"   Hazard Score: {metrics.hazard_score:.3f}")
        print(f"   Exposure Score: {metrics.exposure_score:.3f}")
        print(f"   Vulnerability Score: {metrics.vulnerability_score:.3f}")
        print(f"   Adaptive Capacity Score: {metrics.adaptive_capacity_score:.3f}")
        print(f"   Risk Score: {metrics.risk_score:.3f}")
        
        print(f"\nğŸ“ˆ DETAILED BREAKDOWN:")
        print(f"   Temperature Hazard: {metrics.temperature_hazard:.3f}")
        print(f"   SUHI Hazard: {metrics.suhi_hazard:.3f}")
        print(f"   Air Quality Hazard: {metrics.air_quality_hazard:.3f}")
        print(f"   Water Scarcity Hazard: {metrics.water_scarcity_hazard:.3f}")
        
        print(f"\n   Population Exposure: {metrics.population_exposure:.3f}")
        print(f"   GDP Exposure: {metrics.gdp_exposure:.3f}")
        print(f"   VIIRS Exposure: {metrics.viirs_exposure:.3f}")
        
        print(f"\n   Income Vulnerability: {metrics.income_vulnerability:.3f}")
        print(f"   Age Vulnerability: {metrics.age_vulnerability:.3f}")
        print(f"   Health Vulnerability: {metrics.health_vulnerability:.3f}")
        
    except Exception as e:
        print(f"âŒ Error in assessment: {e}")
        
    print("\n6. WHY EXPOSURE IS LOW:")
    print("-" * 25)
    print("ğŸ” EXPLANATION:")
    print("   Nurafshan has low exposure because it is:")
    print("   â€¢ The smallest city by population (56,200 people)")
    print("   â€¢ Has the lowest population density (1,124/kmÂ²)")
    print("   â€¢ Has relatively low built-up area (23.79%)")
    print("   â€¢ Has low economic activity (nightlights: 2.75)")
    print("   â€¢ Exposure reflects the city's limited assets at risk")
    print("   â€¢ This is correct - smaller cities have less exposure")
    
    print("\nâœ… CONCLUSION: Low exposure score is ACCURATE for Nurafshan")
    print("   - Reflects small population and economic footprint")
    print("   - Fewer assets and people at risk from climate hazards")
    print("   - Percentile normalization shows its relative position")

if __name__ == "__main__":
    test_all_nurafshan_metrics()
